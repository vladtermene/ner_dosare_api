{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "%load_ext autoreload\n",
    "%autoreload 2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from zipfile import ZipFile\n",
    "file_name = 'ronec_step2.zip'\n",
    "\n",
    "with ZipFile(file_name, 'r') as zip:\n",
    "  zip.extractall()\n",
    "  print('Done')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "!pip install -r evaluate/requirements.txt"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training with transformer model / tokenizer: trained_model/dosare_step1/model / dumitrescustefan/bert-base-romanian-cased-v1\n",
      "\t with training file data/train_step2.json\n",
      "\t with validation file data/valid_step2.json\n",
      "\t with test file data/test_step2.json\n",
      "\t batch size is 32, accumulate grad batches is 1, final batch_size is 32\n",
      "\n",
      "Dataset contains 21 BIO2 classes: ['O', 'B-PF', 'I-PF', 'B-PF_reprezentat', 'I-PF_reprezentat', 'B-PF_delegat', 'I-PF_delegat', 'B-PJ', 'I-PJ', 'B-PJ_reprezentat', 'I-PJ_reprezentat', 'B-PJ_delegat', 'I-PJ_delegat', 'B-STAT', 'I-STAT', 'B-STAT_reprezentat', 'I-STAT_reprezentat', 'B-STAT_delegat', 'I-STAT_delegat', 'B-Locatie_PJ', 'I-Locatie_PJ'].\n",
      "\n",
      "There are 11 classes: ['Locatie_PJ', 'O', 'PF', 'PF_delegat', 'PF_reprezentat', 'PJ', 'PJ_delegat', 'PJ_reprezentat', 'STAT', 'STAT_delegat', 'STAT_reprezentat']\n",
      "Loading data ...\n",
      "Train dataset has 3748 instances.\n",
      "Valid dataset has 500 instances.\n",
      "Test dataset has 750 instances.\n",
      "\n",
      "Loading AutoModel [trained_model/dosare_step1/model] ...\n",
      "Some weights of BertForTokenClassification were not initialized from the model checkpoint at trained_model/dosare_step1/model and are newly initialized because the shapes did not match:\n",
      "- classifier.weight: found shape torch.Size([9, 768]) in the checkpoint and torch.Size([21, 768]) in the model instantiated\n",
      "- classifier.bias: found shape torch.Size([9]) in the checkpoint and torch.Size([21]) in the model instantiated\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n",
      "GPU available: False, used: False\n",
      "TPU available: False, using: 0 TPU cores\n",
      "IPU available: False, using: 0 IPUs\n",
      "\n",
      "  | Name  | Type                       | Params\n",
      "-----------------------------------------------------\n",
      "0 | model | BertForTokenClassification | 123 M \n",
      "-----------------------------------------------------\n",
      "123 M     Trainable params\n",
      "0         Non-trainable params\n",
      "123 M     Total params\n",
      "495.468   Total estimated model params size (MB)\n",
      "Validation sanity check: 0it [00:00, ?it/s]/home/vhondru25/Termene/ner_dosare_api/ner_dosare_venv/lib/python3.8/site-packages/pytorch_lightning/trainer/data_loading.py:132: UserWarning: The dataloader, val_dataloader 0, does not have many workers which may be a bottleneck. Consider increasing the value of the `num_workers` argument` (try 16 which is the number of cpus on this machine) in the `DataLoader` init to improve performance.\n",
      "  rank_zero_warn(\n",
      "Validation sanity check: 100%|████████████████████| 2/2 [00:01<00:00,  1.21it/s]\n",
      "/home/vhondru25/Termene/ner_dosare_api/ner_dosare_venv/lib/python3.8/site-packages/pytorch_lightning/trainer/connectors/logger_connector/result.py:226: UserWarning: You called `self.log('valid/strict', ...)` in your `validation_epoch_end` but the value needs to be floating point. Converting it to torch.float32.\n",
      "  warning_cache.warn(\n",
      "/home/vhondru25/Termene/ner_dosare_api/ner_dosare_venv/lib/python3.8/site-packages/pytorch_lightning/trainer/data_loading.py:132: UserWarning: The dataloader, train_dataloader, does not have many workers which may be a bottleneck. Consider increasing the value of the `num_workers` argument` (try 16 which is the number of cpus on this machine) in the `DataLoader` init to improve performance.\n",
      "  rank_zero_warn(\n",
      "Epoch 0:  19%|██▏         | 25/134 [01:16<05:32,  3.05s/it, loss=0.638, v_num=0]^C\n"
     ]
    }
   ],
   "source": [
    "!python3 evaluate/model_step2.py \\\n",
    "--gpus 0 \\\n",
    "--batch_size 32 \\\n",
    "--accumulate_grad_batches 1 \\\n",
    "--model_name trained_model/dosare_step1/model \\\n",
    "--tokenizer_name dumitrescustefan/bert-base-romanian-cased-v1 \\\n",
    "--lr 3e-05 \\\n",
    "--model_max_length 512 \\\n",
    "--train_file data/train_step2.json \\\n",
    "--validation_file data/valid_step2.json \\\n",
    "--test_file data/test_step2.json"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import zipfile\n",
    "    \n",
    "def zipdir(path, ziph):\n",
    "    # ziph is zipfile handle\n",
    "    for root, dirs, files in os.walk(path):\n",
    "        for file in files:\n",
    "            ziph.write(os.path.join(root, file), \n",
    "                       os.path.relpath(os.path.join(root, file), \n",
    "                                       os.path.join(path, '..')))\n",
    "      \n",
    "zipf = zipfile.ZipFile('dosare_step2.zip', 'w', zipfile.ZIP_DEFLATED)\n",
    "zipdir('trained_model/', zipf)\n",
    "zipf.close()"
   ]
  }
 ],
 "metadata": {
  "interpreter": {
   "hash": "e0895277591e3914d9ac5e133e0668da33d0c2c056c34d0da196f324ecb49b43"
  },
  "kernelspec": {
   "display_name": "Python 3.8.10 64-bit ('venv': venv)",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.10"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
