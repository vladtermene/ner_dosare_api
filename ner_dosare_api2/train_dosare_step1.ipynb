{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "%load_ext autoreload\n",
    "%autoreload 2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from zipfile import ZipFile\n",
    "file_name = 'ronec_step1.zip'\n",
    "\n",
    "with ZipFile(file_name, 'r') as zip:\n",
    "  zip.extractall()\n",
    "  print('Done')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "!pip install -r evaluate/requirements.txt"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training with transformer model / tokenizer: dumitrescustefan/bert-base-romanian-cased-v1 / dumitrescustefan/bert-base-romanian-cased-v1\n",
      "\t with training file data/train.json\n",
      "\t with validation file data/valid.json\n",
      "\t with test file data/test.json\n",
      "\t batch size is 16, accumulate grad batches is 2, final batch_size is 32\n",
      "\n",
      "Dataset contains 63 BIO2 classes: ['O', 'B-Tip_buletin', 'I-Tip_buletin', 'B-Nr_buletin', 'I-Nr_buletin', 'B-Nr_dosar', 'I-Nr_dosar', 'B-Instanta', 'I-Instanta', 'B-Sectia', 'I-Sectia', 'B-Judecator', 'I-Judecator', 'B-Nume_debitor', 'I-Nume_debitor', 'B-CUI_debitor', 'I-CUI_debitor', 'B-Adresa_debitor', 'I-Adresa_debitor', 'B-J_debitor', 'I-J_debitor', 'B-Calitate_admin', 'I-Calitate_admin', 'B-Nume_admin', 'I-Nume_admin', 'B-Nedesemnat_admin', 'I-Nedesemnat_admin', 'B-CUI_admin', 'I-CUI_admin', 'B-RFO_admin', 'I-RFO_admin', 'B-Adresa_admin', 'I-Adresa_admin', 'B-Email_admin', 'I-Email_admin', 'B-Telefon_admin', 'I-Telefon_admin', 'B-Reprezentant_admin', 'I-Reprezentant_admin', 'B-Nume_creditor', 'I-Nume_creditor', 'B-CUI_creditor', 'I-CUI_creditor', 'B-Adresa_creditor', 'I-Adresa_creditor', 'B-J_creditor', 'I-J_creditor', 'B-Descriere_termen', 'I-Descriere_termen', 'B-Data_termen', 'I-Data_termen', 'B-Nume_adunare', 'I-Nume_adunare', 'B-OrdineDeZi_adunare', 'I-OrdineDeZi_adunare', 'B-Data_adunare', 'I-Data_adunare', 'B-Ora_adunare', 'I-Ora_adunare', 'B-Locatie_adunare', 'I-Locatie_adunare', 'B-Restrictii_creditori', 'I-Restrictii_creditori'].\n",
      "\n",
      "There are 32 classes: ['Adresa_admin', 'Adresa_creditor', 'Adresa_debitor', 'CUI_admin', 'CUI_creditor', 'CUI_debitor', 'Calitate_admin', 'Data_adunare', 'Data_termen', 'Descriere_termen', 'Email_admin', 'Instanta', 'J_creditor', 'J_debitor', 'Judecator', 'Locatie_adunare', 'Nedesemnat_admin', 'Nr_buletin', 'Nr_dosar', 'Nume_admin', 'Nume_adunare', 'Nume_creditor', 'Nume_debitor', 'O', 'Ora_adunare', 'OrdineDeZi_adunare', 'RFO_admin', 'Reprezentant_admin', 'Restrictii_creditori', 'Sectia', 'Telefon_admin', 'Tip_buletin']\n",
      "Loading data ...\n",
      "Train dataset has 9375 instances.\n",
      "Valid dataset has 1250 instances.\n",
      "Test dataset has 1875 instances.\n",
      "\n",
      "Loading AutoModel [dumitrescustefan/bert-base-romanian-cased-v1] ...\n",
      "Some weights of the model checkpoint at dumitrescustefan/bert-base-romanian-cased-v1 were not used when initializing BertForTokenClassification: ['cls.predictions.decoder.bias', 'cls.predictions.transform.LayerNorm.weight', 'cls.predictions.transform.LayerNorm.bias', 'cls.predictions.transform.dense.weight', 'cls.seq_relationship.bias', 'cls.predictions.decoder.weight', 'cls.predictions.transform.dense.bias', 'cls.predictions.bias', 'cls.seq_relationship.weight']\n",
      "- This IS expected if you are initializing BertForTokenClassification from the checkpoint of a model trained on another task or with another architecture (e.g. initializing a BertForSequenceClassification model from a BertForPreTraining model).\n",
      "- This IS NOT expected if you are initializing BertForTokenClassification from the checkpoint of a model that you expect to be exactly identical (initializing a BertForSequenceClassification model from a BertForSequenceClassification model).\n",
      "Some weights of BertForTokenClassification were not initialized from the model checkpoint at dumitrescustefan/bert-base-romanian-cased-v1 and are newly initialized: ['classifier.bias', 'classifier.weight']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n",
      "GPU available: False, used: False\n",
      "TPU available: False, using: 0 TPU cores\n",
      "IPU available: False, using: 0 IPUs\n",
      "\n",
      "  | Name  | Type                       | Params\n",
      "-----------------------------------------------------\n",
      "0 | model | BertForTokenClassification | 123 M \n",
      "-----------------------------------------------------\n",
      "123 M     Trainable params\n",
      "0         Non-trainable params\n",
      "123 M     Total params\n",
      "495.597   Total estimated model params size (MB)\n",
      "Validation sanity check: 0it [00:00, ?it/s]/home/vhondru25/Termene/ronec/venv/lib/python3.8/site-packages/pytorch_lightning/trainer/data_loading.py:105: UserWarning: The dataloader, val dataloader 0, does not have many workers which may be a bottleneck. Consider increasing the value of the `num_workers` argument` (try 16 which is the number of cpus on this machine) in the `DataLoader` init to improve performance.\n",
      "  rank_zero_warn(\n",
      "Validation sanity check: 100%|████████████████████| 2/2 [00:08<00:00,  4.20s/it]\n",
      "/home/vhondru25/Termene/ronec/venv/lib/python3.8/site-packages/pytorch_lightning/trainer/data_loading.py:105: UserWarning: The dataloader, train dataloader, does not have many workers which may be a bottleneck. Consider increasing the value of the `num_workers` argument` (try 16 which is the number of cpus on this machine) in the `DataLoader` init to improve performance.\n",
      "  rank_zero_warn(\n",
      "Epoch 0:   1%|▏           | 8/665 [01:30<1:50:35, 10.10s/it, loss=3.68, v_num=2]^C\n"
     ]
    }
   ],
   "source": [
    "!python3 evaluate/model_step1.py \\\n",
    "--gpus 1 \\\n",
    "--batch_size 32 \\\n",
    "--accumulate_grad_batches 1 \\\n",
    "--model_name dumitrescustefan/bert-base-romanian-cased-v1 \\\n",
    "--lr 3e-05 \\\n",
    "--model_max_length 512 \\\n",
    "--train_file data/train_step1.json \\\n",
    "--validation_file data/valid_step1.json \\\n",
    "--test_file data/test_step1.json"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import zipfile\n",
    "    \n",
    "def zipdir(path, ziph):\n",
    "    # ziph is zipfile handle\n",
    "    for root, dirs, files in os.walk(path):\n",
    "        for file in files:\n",
    "            ziph.write(os.path.join(root, file), \n",
    "                       os.path.relpath(os.path.join(root, file), \n",
    "                                       os.path.join(path, '..')))\n",
    "      \n",
    "zipf = zipfile.ZipFile('dosare_step1.zip', 'w', zipfile.ZIP_DEFLATED)\n",
    "zipdir('trained_model/', zipf)\n",
    "zipf.close()"
   ]
  }
 ],
 "metadata": {
  "interpreter": {
   "hash": "e0895277591e3914d9ac5e133e0668da33d0c2c056c34d0da196f324ecb49b43"
  },
  "kernelspec": {
   "display_name": "Python 3.8.10 64-bit ('venv': venv)",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.10"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
